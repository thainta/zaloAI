{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ZALO_AI_TASK1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0xC99JgPzA51X9t+mbpi6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thainta/zaloAI/blob/main/ZALO_AI_TASK1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-rvguzW6RTo"
      },
      "source": [
        "##GET DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v0wa0ZR5iOJ",
        "outputId": "ae542334-c93c-40ea-ad11-7cd072bc9d8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! wget https://dl.challenge.zalo.ai/news-summarization/data/train.zip\n",
        "! wget https://dl.challenge.zalo.ai/news-summarization/data/public_test.zip \n",
        "! wget https://dl.challenge.zalo.ai/news-summarization/data/public_test_sample_submit.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-14 04:13:55--  https://dl.challenge.zalo.ai/news-summarization/data/train.zip\n",
            "Resolving dl.challenge.zalo.ai (dl.challenge.zalo.ai)... 49.213.78.231\n",
            "Connecting to dl.challenge.zalo.ai (dl.challenge.zalo.ai)|49.213.78.231|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1224058 (1.2M) [application/zip]\n",
            "Saving to: ‘train.zip’\n",
            "\n",
            "train.zip           100%[===================>]   1.17M  1.42MB/s    in 0.8s    \n",
            "\n",
            "2020-11-14 04:13:57 (1.42 MB/s) - ‘train.zip’ saved [1224058/1224058]\n",
            "\n",
            "--2020-11-14 04:13:57--  https://dl.challenge.zalo.ai/news-summarization/data/public_test.zip\n",
            "Resolving dl.challenge.zalo.ai (dl.challenge.zalo.ai)... 49.213.78.231\n",
            "Connecting to dl.challenge.zalo.ai (dl.challenge.zalo.ai)|49.213.78.231|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 319489 (312K) [application/zip]\n",
            "Saving to: ‘public_test.zip’\n",
            "\n",
            "public_test.zip     100%[===================>] 312.00K   627KB/s    in 0.5s    \n",
            "\n",
            "2020-11-14 04:13:58 (627 KB/s) - ‘public_test.zip’ saved [319489/319489]\n",
            "\n",
            "--2020-11-14 04:13:59--  https://dl.challenge.zalo.ai/news-summarization/data/public_test_sample_submit.zip\n",
            "Resolving dl.challenge.zalo.ai (dl.challenge.zalo.ai)... 49.213.78.231\n",
            "Connecting to dl.challenge.zalo.ai (dl.challenge.zalo.ai)|49.213.78.231|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1833 (1.8K) [application/zip]\n",
            "Saving to: ‘public_test_sample_submit.zip’\n",
            "\n",
            "public_test_sample_ 100%[===================>]   1.79K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-11-14 04:13:59 (329 MB/s) - ‘public_test_sample_submit.zip’ saved [1833/1833]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or_EyhuX6Lnb",
        "outputId": "46312941-d700-490f-9bca-ec3be04025f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! unzip public_test.zip\n",
        "! unzip public_test_sample_submit.zip\n",
        "! unzip train.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  public_test.zip\n",
            "   creating: public_test/public_test/\n",
            "  inflating: public_test/public_test/public_test.jsonl  \n",
            " extracting: public_test/public_test/export_date.txt  \n",
            "Archive:  public_test_sample_submit.zip\n",
            "   creating: public_test/public_test_sample_submit/\n",
            "  inflating: public_test/public_test_sample_submit/public_test_sample_submit.jsonl  \n",
            "Archive:  train.zip\n",
            "   creating: train/\n",
            "  inflating: train/train.jsonl       \n",
            " extracting: train/export_date.txt   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60IBCnRe6eyg"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 1000)\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "train = pd.read_json(\"/content/train/train.jsonl\", lines = True)\n",
        "test  = pd.read_json(\"/content/public_test/public_test/public_test.jsonl\", lines = True)\n",
        "public_test_sample = pd.read_json(\"/content/public_test/public_test_sample_submit/public_test_sample_submit.jsonl\",lines = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYdYaXjF6p3f"
      },
      "source": [
        "# TRAIN NAME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-ThitvA6v-i",
        "outputId": "ffa7bbb4-ccbf-478d-ff3a-4c9b558e7716",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/58/a4a65efcce5c81a67b6893ade862736de355a3a718af5533d30c991831ce/ipython_autotime-0.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (50.3.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.3.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.2.0\n",
            "time: 168 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtW04CMD6v9l",
        "outputId": "05e35fae-44a7-4af3-b8fa-7a7cef3bb03e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install vncorenlp\n",
        "! wget https://github.com/vncorenlp/VnCoreNLP/archive/master.zip\n",
        "! wget http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\n",
        "! unzip master.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vncorenlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/c2/96a60cf75421ecc740829fa920c617b3dd7fa6791e17554e7c6f3e7d7fca/vncorenlp-1.0.3.tar.gz (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vncorenlp) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (1.24.3)\n",
            "Building wheels for collected packages: vncorenlp\n",
            "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-cp36-none-any.whl size=2645934 sha256=b795ec056778ee1e35efebfadf12d720dc64867d9030c265504a0b93afe1d15a\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/54/8b/043667de6091d06a381d7745f44174504a9a4a56ecc9380c54\n",
            "Successfully built vncorenlp\n",
            "Installing collected packages: vncorenlp\n",
            "Successfully installed vncorenlp-1.0.3\n",
            "--2020-11-14 04:20:19--  https://github.com/vncorenlp/VnCoreNLP/archive/master.zip\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/vncorenlp/VnCoreNLP/zip/master [following]\n",
            "--2020-11-14 04:20:20--  https://codeload.github.com/vncorenlp/VnCoreNLP/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 192.30.255.120\n",
            "Connecting to codeload.github.com (codeload.github.com)|192.30.255.120|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [       <=>          ] 137.29M  26.3MB/s    in 5.2s    \n",
            "\n",
            "2020-11-14 04:20:25 (26.3 MB/s) - ‘master.zip’ saved [143955752]\n",
            "\n",
            "--2020-11-14 04:20:25--  http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\n",
            "Resolving www.oracle.com (www.oracle.com)... 69.192.215.235, 2600:1409:d000:593::a15, 2600:1409:d000:58b::a15\n",
            "Connecting to www.oracle.com (www.oracle.com)|69.192.215.235|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html [following]\n",
            "--2020-11-14 04:20:25--  https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\n",
            "Connecting to www.oracle.com (www.oracle.com)|69.192.215.235|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html [following]\n",
            "--2020-11-14 04:20:25--  https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html\n",
            "Connecting to www.oracle.com (www.oracle.com)|69.192.215.235|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘jdk8-downloads-2133151.html’\n",
            "\n",
            "jdk8-downloads-2133     [ <=>                ]  46.97K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-11-14 04:20:26 (1.95 MB/s) - ‘jdk8-downloads-2133151.html’ saved [48098]\n",
            "\n",
            "Archive:  master.zip\n",
            "8a90af008e4866ed07a75af9e2a00a489c2ffb28\n",
            "   creating: VnCoreNLP-master/\n",
            "  inflating: VnCoreNLP-master/LICENSE.md  \n",
            "  inflating: VnCoreNLP-master/Readme.md  \n",
            "  inflating: VnCoreNLP-master/TagsetDescription.md  \n",
            "  inflating: VnCoreNLP-master/VLSP2013_POS_tagset.pdf  \n",
            "  inflating: VnCoreNLP-master/VnCoreNLP-1.1.1.jar  \n",
            "  inflating: VnCoreNLP-master/VnDT-treebank-description.pdf  \n",
            "   creating: VnCoreNLP-master/models/\n",
            "   creating: VnCoreNLP-master/models/dep/\n",
            " extracting: VnCoreNLP-master/models/dep/vi-dep.xz  \n",
            "   creating: VnCoreNLP-master/models/ner/\n",
            " extracting: VnCoreNLP-master/models/ner/vi-500brownclusters.xz  \n",
            " extracting: VnCoreNLP-master/models/ner/vi-ner.xz  \n",
            " extracting: VnCoreNLP-master/models/ner/vi-pretrainedembeddings.xz  \n",
            "   creating: VnCoreNLP-master/models/postagger/\n",
            " extracting: VnCoreNLP-master/models/postagger/vi-tagger  \n",
            "   creating: VnCoreNLP-master/models/wordsegmenter/\n",
            "  inflating: VnCoreNLP-master/models/wordsegmenter/vi-vocab  \n",
            "  inflating: VnCoreNLP-master/models/wordsegmenter/wordsegmenter.rdr  \n",
            "  inflating: VnCoreNLP-master/pom.xml  \n",
            "   creating: VnCoreNLP-master/src/\n",
            "   creating: VnCoreNLP-master/src/main/\n",
            "   creating: VnCoreNLP-master/src/main/java/\n",
            "   creating: VnCoreNLP-master/src/main/java/vn/\n",
            "   creating: VnCoreNLP-master/src/main/java/vn/corenlp/\n",
            "   creating: VnCoreNLP-master/src/main/java/vn/corenlp/ner/\n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/corenlp/ner/NerRecognizer.java  \n",
            "   creating: VnCoreNLP-master/src/main/java/vn/corenlp/parser/\n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/corenlp/parser/DependencyParser.java  \n",
            "   creating: VnCoreNLP-master/src/main/java/vn/corenlp/postagger/\n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/corenlp/postagger/PosTagger.java  \n",
            "   creating: VnCoreNLP-master/src/main/java/vn/corenlp/tokenizer/\n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/corenlp/tokenizer/StringUtils.java  \n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/corenlp/tokenizer/Tokenizer.java  \n",
            "   creating: VnCoreNLP-master/src/main/java/vn/corenlp/wordsegmenter/\n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/corenlp/wordsegmenter/FWObject.java  \n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/corenlp/wordsegmenter/Node.java  \n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/corenlp/wordsegmenter/Utils.java  \n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/corenlp/wordsegmenter/Vocabulary.java  \n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/corenlp/wordsegmenter/WordSegmenter.java  \n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/corenlp/wordsegmenter/WordTag.java  \n",
            "   creating: VnCoreNLP-master/src/main/java/vn/pipeline/\n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/pipeline/Annotation.java  \n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/pipeline/LexicalInitializer.java  \n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/pipeline/Sentence.java  \n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/pipeline/Utils.java  \n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/pipeline/VnCoreNLP.java  \n",
            "  inflating: VnCoreNLP-master/src/main/java/vn/pipeline/Word.java  \n",
            "   creating: VnCoreNLP-master/src/main/resources/\n",
            "  inflating: VnCoreNLP-master/src/main/resources/log4j.properties  \n",
            "   creating: VnCoreNLP-master/src/test/\n",
            "   creating: VnCoreNLP-master/src/test/java/\n",
            "  inflating: VnCoreNLP-master/src/test/java/VnCoreNLPExample.java  \n",
            "time: 12.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6akJmWE27NcH"
      },
      "source": [
        "IMPORT LIB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTSm6VdF7Q2i",
        "outputId": "93b3f570-c793-451a-ef51-7affec71da97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from vncorenlp import VnCoreNLP\n",
        "from collections import Counter\n",
        "import pprint as pp\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 71 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87Qxs1PV8OA-",
        "outputId": "20f4d20e-7865-4eba-a51f-90bc5ad17fc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vncorenlp_file = '/content/VnCoreNLP-master/VnCoreNLP-1.1.1.jar'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.03 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fna-k0CQ8PPB"
      },
      "source": [
        "TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r6eiJ8BOxB3",
        "outputId": "e7aca7c6-78e3-4ba3-fe02-b5a19bb0194f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "list_dict = []\n",
        "for p in range(19,20): \n",
        "  text = test['original_doc'][p]\n",
        "  test_id = test['test_id'][p]\n",
        "  size_temp = len(text[\"_source\"][\"body\"])\n",
        "  sentences = [] \n",
        "  for p in range(size_temp):\n",
        "    temp = ((text[\"_source\"][\"body\"][p][\"text\"]))\n",
        "    sentences.append(temp)\n",
        "  s = str()\n",
        "  s = s + ' ' + ' '.join(sentences)\n",
        "  s = s + '. ' + str(text[\"_source\"][\"description\"])\n",
        "  clean_text = s\n",
        "  scores =  []\n",
        "  for j in range(len(clean_text)):\n",
        "    if clean_text[j] == '-' and clean_text[j+2]!='-' and clean_text[j-2]!='-':\n",
        "      if clean_text[j-1].isnumeric() and clean_text[j+1].isnumeric():\n",
        "        scores.append(clean_text[j-1]+clean_text[j]+clean_text[j+1])\n",
        "    if clean_text[j] == '-' and clean_text[j-2].isnumeric() and clean_text[j+2].isnumeric():\n",
        "      scores.append(clean_text[j-2]+clean_text[j]+clean_text[j+2])\n",
        "  listA = scores\n",
        "  scores_occurence_count = Counter(listA)\n",
        "  final_score_1=scores_occurence_count.most_common(1)[0][0][0]\n",
        "  final_score_2=scores_occurence_count.most_common(1)[0][0][2]\n",
        "  #print(clean_text)\n",
        "  with VnCoreNLP(vncorenlp_file) as vncorenlp:\n",
        "    ner = list(vncorenlp.ner(clean_text))\n",
        "  print(ner)\n",
        "  ner_merge = sum(ner,[])\n",
        "  soccer_team = [list(x) for x in ner_merge if x[1] == 'B-ORG' or x[1] =='I-ORG' or x[1] =='B-LOC' or x[1] =='I-LOC']\n",
        "  i = 0\n",
        "  while i< (len(soccer_team)):\n",
        "    if i == len(soccer_team) - 1 and soccer_team[i][1] != 'I-LOC' and soccer_team[i][1] != 'I-ORG':\n",
        "      break\n",
        "    if soccer_team[i][1] == 'B-ORG' and soccer_team[i+1][1] == 'I-ORG':\n",
        "      soccer_team[i][0] = soccer_team[i][0] + ' '+ soccer_team[i+1][0]\n",
        "      soccer_team.pop(i+1)\n",
        "    if soccer_team[i][1] == 'B-LOC' and soccer_team[i+1][1] == 'I-LOC':\n",
        "      if soccer_team[i][0][len(soccer_team[i][0])-1] == '.':\n",
        "        soccer_team[i][0] = soccer_team[i][0] +soccer_team[i+1][0]\n",
        "      else:  \n",
        "        soccer_team[i][0] = soccer_team[i][0] + ' ' +soccer_team[i+1][0]\n",
        "      soccer_team.pop(i+1)\n",
        "    i+=1\n",
        "  i = 0\n",
        "  while i < len(soccer_team)-1:\n",
        "    j = i+1\n",
        "    while j < len(soccer_team):\n",
        "      if (soccer_team[i][0] != soccer_team[j][0]):\n",
        "        if (soccer_team[i][0] in soccer_team[j][0]) or (soccer_team[j][0] in soccer_team[i][0]):\n",
        "          if (soccer_team.count(soccer_team[i]) > soccer_team.count(soccer_team[j])) :\n",
        "            t = soccer_team[j]\n",
        "            soccer_team = [x for x in soccer_team if x!= t ]\n",
        "          else :\n",
        "            t = soccer_team[i]\n",
        "            soccer_team = [x for x in soccer_team if x!= t ]\n",
        "          i = 0\n",
        "          j = i+1\n",
        "          continue      \n",
        "      j+=1\n",
        "    i+=1\n",
        "  trash_can = []\n",
        "  i = 0\n",
        "  while i < len(soccer_team):\n",
        "    if soccer_team[i][0] in trash_can:\n",
        "      i+=1\n",
        "      continue\n",
        "    if soccer_team[i][0][0].islower():\n",
        "      t = soccer_team[i]\n",
        "      soccer_team = [x for x in soccer_team if x!= t]\n",
        "      trash_can.append(t)\n",
        "    i+=1\n",
        "  listA = []\n",
        "  for x in soccer_team:\n",
        "    listA.append(tuple(x))\n",
        "  #print(\"Given List:\\n\",listA)\n",
        "  team_occurence_count = Counter(listA)\n",
        "  team1=team_occurence_count.most_common(2)[0][0][0]\n",
        "  team1 = team1.replace('_',' ')\n",
        "  team2 = team_occurence_count.most_common(2)[1][0][0]\n",
        "  team2 = team2.replace('_',' ')\n",
        "  d = {\"test_id\": \"%d\"%(test_id), \"match_summary\": {\"players\": {\"team1\": \"%s\"%team1, \"team2\": \"%s\"%team2}, \"score_board\": {\"score1\": \"0\", \"score2\": \"0\"}, \"score_list\": [{\"player_name\": \"\", \"time\": \"\", \"team\": \"\"}], \"card_list\": [{\"player_name\": \"\", \"time\": \"\", \"team\": \"\"}], \"substitution_list\": [{\"player_in\": \"\", \"time\": \"\", \"player_out\": \"\"}]}}\n",
        "  list_dict.append(d)\n",
        "  ##print(d)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[('Pha', 'O'), ('sút', 'O'), ('bóng', 'O'), ('của', 'O'), ('cầu_thủ', 'O'), ('Sanna_Khánh', 'B-PER'), ('Hoà-BVN', 'I-PER'), ('(', 'O'), ('quần_áo', 'O'), ('xanh', 'O'), (')', 'O'), ('.', 'O')], [('(', 'O'), ('Ảnh', 'O'), (':', 'O'), ('Tiên_Minh', 'B-PER'), ('/', 'O'), ('TTXVN', 'B-ORG'), (')', 'O'), ('Chiều', 'O'), ('12/2', 'O'), (',', 'O'), ('trên', 'O'), ('sân', 'O'), ('19/8', 'O'), (',', 'O'), ('thành_phố', 'B-LOC'), ('Nha_Trang', 'I-LOC'), ('(', 'O'), ('Khánh_Hoà', 'B-LOC'), (')', 'O'), (',', 'O'), ('đội', 'O'), ('bóng', 'O'), ('chủ', 'O'), ('nhà', 'O'), ('Sanna_Khánh', 'O'), ('Hoà-BVN', 'B-PER'), ('đã', 'O'), ('không_thể', 'O'), ('chống_đỡ', 'O'), ('những', 'O'), ('chân', 'O'), ('sút', 'O'), ('đầy', 'O'), ('hiệu_quả', 'O'), ('của', 'O'), ('Than_Quang_Ninh', 'B-PER'), (',', 'O'), ('chấp_nhận', 'O'), ('thua', 'O'), ('đậm', 'O'), ('0-3', 'O'), ('sau', 'O'), ('khi', 'O'), ('tiếng', 'O'), ('còi', 'O'), ('kết_thúc', 'O'), ('trận', 'O'), ('đấu', 'O'), ('của', 'O'), ('trọng_tài', 'O'), ('Võ_Minh_Trí', 'B-PER'), ('vang', 'O'), ('lên', 'O'), ('.', 'O')], [('Mặc_dù', 'O'), ('Sanna_Khánh', 'O'), ('Hoà-BVN', 'O'), ('giành', 'O'), ('trọn', 'O'), ('6', 'O'), ('điểm', 'O'), ('trước', 'O'), ('Than_Quảng_Ninh', 'B-ORG'), ('trong', 'O'), ('mùa', 'O'), ('giải', 'O'), ('trước', 'O'), (',', 'O'), ('nhưng', 'O'), ('phần_lớn', 'O'), ('nhờ', 'O'), ('vào', 'O'), ('công', 'O'), ('của', 'O'), ('tiền_đạo', 'O'), ('ngoại', 'O'), ('Uche', 'B-PER'), ('.', 'O')], [('Giải', 'O'), ('năm', 'O'), ('nay', 'O'), ('khi', 'O'), ('Uche', 'B-PER'), ('chuyển', 'O'), ('sang', 'O'), ('thi_đấu', 'O'), ('cho', 'O'), ('FLC', 'B-ORG'), ('Thanh_Hoá', 'I-ORG'), (',', 'O'), ('giới', 'O'), ('chuyên_môn', 'O'), ('đánh_giá', 'O'), ('trước', 'O'), ('trận', 'O'), ('đấu', 'O'), ('rằng', 'O'), (',', 'O'), ('đội', 'O'), ('khách', 'O'), ('Than_Quảng_Ninh', 'B-ORG'), ('trở_nên', 'O'), ('vượt_trội', 'O'), (',', 'O'), ('sẽ', 'O'), ('dễ_dàng', 'O'), ('giành', 'O'), ('trọn', 'O'), ('3', 'O'), ('điểm', 'O'), ('khi', 'O'), ('đến', 'O'), ('làm_khách', 'O'), ('ở', 'O'), ('thành_phố', 'O'), ('biển', 'O'), ('Nha_Trang', 'B-LOC'), ('.', 'O')], [('Vào', 'O'), ('hiệp', 'O'), ('1', 'O'), (',', 'O'), ('trận', 'O'), ('đấu', 'O'), ('sau', 'O'), ('kỳ', 'O'), ('nghỉ', 'O'), ('Tết', 'O'), ('kéo_dài', 'O'), ('dường_như', 'O'), ('đã', 'O'), ('ảnh_hưởng', 'O'), ('khi', 'O'), ('cả', 'O'), ('hai', 'O'), ('đội', 'O'), ('nhập_cuộc', 'O'), ('khá', 'O'), ('thong_thả', 'O'), ('.', 'O')], [('Bầu_không_khí', 'O'), ('thực_sự', 'O'), ('được', 'O'), ('hâm_nóng', 'O'), ('và', 'O'), ('trở_nên', 'O'), ('sôi_động', 'O'), ('vào', 'O'), ('phút', 'O'), ('thứ', 'O'), ('17', 'O'), (',', 'O'), ('khi', 'O'), ('Than_Quảng_Ninh', 'B-ORG'), ('thực_hiện', 'O'), ('quả', 'O'), ('phạt_góc', 'O'), ('từ', 'O'), ('cánh', 'O'), ('phải', 'O'), ('và', 'O'), ('đưa', 'O'), ('bóng', 'O'), ('vào', 'O'), ('khu_vực', 'O'), ('cấm', 'O'), ('đối_phương', 'O'), (',', 'O'), ('khiến', 'O'), ('hàng', 'O'), ('phòng_thủ', 'O'), ('của', 'O'), ('Sanna_Khánh_Hoà', 'B-PER'), ('phạm', 'O'), ('lỗi', 'O'), (',', 'O'), ('giúp', 'O'), ('Than_Quảng_Ninh', 'B-ORG'), ('hưởng', 'O'), ('quả', 'O'), ('phạt_đền', 'O'), ('trực_tiếp', 'O'), ('.', 'O')], [('Tiền_đạo', 'O'), ('Vũ_Minh_Tuấn', 'B-PER'), ('mang', 'O'), ('băng', 'O'), ('đội_trưởng', 'O'), ('của', 'O'), ('đội', 'O'), ('khách', 'O'), ('đã', 'O'), ('không', 'O'), ('khó_khăn', 'O'), ('đưa', 'O'), ('bóng', 'O'), ('vào', 'O'), ('lưới', 'O'), (',', 'O'), ('mở', 'O'), ('tỷ_số', 'O'), ('1-0', 'O'), ('cho', 'O'), ('Than_Quảng_Ninh', 'B-ORG'), ('.', 'O')], [('Kể', 'O'), ('từ', 'O'), ('đó', 'O'), (',', 'O'), ('các', 'O'), ('cầu_thủ', 'O'), ('Sanna_Khánh', 'O'), ('Hoà-BVN', 'O'), ('như', 'O'), ('bừng', 'O'), ('tỉnh', 'O'), (',', 'O'), ('dâng', 'O'), ('cao', 'O'), ('đội_hình', 'O'), ('tấn_công', 'O'), ('và', 'O'), ('tạo', 'O'), ('nên', 'O'), ('những', 'O'), ('tình_huống', 'O'), ('nguy_hiểm', 'O'), ('cho', 'O'), ('khung_thành', 'O'), ('đối_thủ', 'O'), (',', 'O'), ('tuy_nhiên', 'O'), ('bóng', 'O'), ('đã', 'O'), ('không', 'O'), ('đến', 'O'), ('được', 'O'), ('điểm', 'O'), ('đích', 'O'), ('.', 'O')], [('Khi', 'O'), ('hiệp', 'O'), ('1', 'O'), ('vừa', 'O'), ('được', 'O'), ('thông_báo', 'O'), ('có', 'O'), ('2', 'O'), ('phút', 'O'), ('đá', 'O'), ('bù', 'O'), ('giờ', 'O'), (',', 'O'), ('cũng', 'O'), ('là', 'O'), ('lúc', 'O'), ('Than_Quảng_Ninh', 'B-ORG'), ('có', 'O'), ('đợt', 'O'), ('tấn_công', 'O'), ('áp', 'O'), ('sát', 'O'), ('vùng', 'O'), ('cấm', 'O'), ('của', 'O'), ('đối_thủ', 'O'), (',', 'O'), ('buộc', 'O'), ('thủ_môn', 'O'), ('Tuấn_Mạnh', 'B-PER'), ('phá', 'O'), ('bóng', 'O'), ('ra', 'O'), ('ngoài', 'O'), ('.', 'O')], [('Rủi', 'O'), ('thay', 'O'), (',', 'O'), ('bóng', 'O'), ('đã', 'O'), ('trúng', 'O'), ('vào', 'O'), ('người', 'O'), ('của', 'O'), ('hậu_vệ', 'O'), ('chủ', 'O'), ('nhà', 'O'), ('Đình_Nhơn', 'B-PER'), ('và', 'O'), ('bật', 'O'), ('ngược', 'O'), ('vào', 'O'), ('lưới', 'O'), ('nhà', 'O'), (',', 'O'), ('giúp', 'O'), ('Than_Quảng_Ninh', 'B-ORG'), ('nâng', 'O'), ('tỷ_số', 'O'), ('lên', 'O'), ('2-0', 'O'), ('.', 'O')], [('Vào', 'O'), ('hiệp', 'O'), ('hai', 'O'), (',', 'O'), ('thế_trận', 'O'), ('có', 'O'), ('phần', 'O'), ('cân_bằng', 'O'), ('với', 'O'), ('những', 'O'), ('pha', 'O'), ('tấn_công', 'O'), ('khá', 'O'), ('hiểm', 'O'), ('từ', 'O'), ('hai', 'O'), ('phía', 'O'), ('.', 'O')], [('Song', 'O'), ('những', 'O'), ('chân', 'O'), ('sút', 'O'), ('của', 'O'), ('Sanna_Khánh', 'O'), ('Hoà-BVN', 'O'), ('đều', 'O'), ('bị', 'O'), ('các', 'O'), ('cầu_thủ', 'O'), ('Than_Quảng_Ninh', 'B-ORG'), ('cản_phá', 'O'), ('.', 'O')], [('Đội', 'O'), ('khách', 'O'), ('đã', 'O'), ('nâng', 'O'), ('tỷ_số', 'O'), ('lên', 'O'), ('3', 'O'), ('–', 'O'), ('0', 'O'), ('vào', 'O'), ('phút', 'O'), ('91', 'O'), ('của', 'O'), ('trận', 'O'), ('đấu', 'O'), (',', 'O'), ('do', 'O'), ('tiền_đạo', 'O'), ('Patiyo', 'B-PER'), ('lập_công', 'O'), ('.', 'O')], [('Thắng', 'O'), ('trận', 'O'), ('này', 'O'), (',', 'O'), ('thầy_trò', 'O'), ('huấn_luyện_viên', 'O'), ('Phan_Thanh_Hùng', 'B-PER'), ('của', 'O'), ('Than_Quảng_Ninh', 'B-ORG'), ('đã', 'O'), ('có', 'O'), ('6', 'O'), ('điểm', 'O'), (',', 'O'), ('vượt', 'O'), ('qua', 'O'), ('Sanna_Khánh', 'O'), ('Hoà-BVN', 'O'), ('với', 'O'), ('5', 'O'), ('điểm', 'O'), ('trong', 'O'), ('bảng', 'O'), ('xếp_hạng', 'O'), ('tạm_thời', 'O'), ('sau', 'O'), ('5', 'O'), ('vòng', 'O'), ('đấu', 'O'), ('.', 'O')], [('Đây', 'O'), ('cũng', 'O'), ('là', 'O'), ('trận', 'O'), ('thứ', 'O'), ('hai', 'O'), ('liên_tiếp', 'O'), (',', 'O'), ('Sanna_Khánh', 'O'), ('Hoà-BVN', 'O'), ('đá', 'O'), ('trên', 'O'), ('sân_nhà', 'O'), ('nhưng', 'O'), ('đều', 'O'), ('“', 'O'), ('nhường', 'O'), ('”', 'O'), ('hết', 'O'), ('điểm', 'O'), ('cho', 'O'), ('các', 'O'), ('đội', 'O'), ('khách', 'O'), ('.', 'O')], [('/', 'O'), ('..', 'O')], [('Đội', 'O'), ('chủ', 'O'), ('nhà', 'O'), ('Sanna_Khánh', 'O'), ('Hoà-BVN', 'B-PER'), ('đã', 'O'), ('không_thể', 'O'), ('chống_đỡ', 'O'), ('những', 'O'), ('chân', 'O'), ('sút', 'O'), ('đầy', 'O'), ('hiệu_quả', 'O'), ('của', 'O'), ('Than_Quang_Ninh', 'B-PER'), (',', 'O'), ('chấp_nhận', 'O'), ('thua', 'O'), ('đậm', 'O'), ('0-3', 'O'), ('sau', 'O'), ('khi', 'O'), ('tiếng', 'O'), ('còi', 'O'), ('kết_thúc', 'O'), ('trận', 'O'), ('đấu', 'O'), ('của', 'O'), ('trọng_tài', 'O'), ('Võ_Minh_Trí', 'B-PER'), ('vang', 'O'), ('lên', 'O'), ('.', 'O')]]\n",
            "time: 45.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOY3HzLD8ix5"
      },
      "source": [
        "WRITE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0pidDhI8koH",
        "outputId": "eceb76f1-9e67-467b-e273-0735bdf6b716",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with open('submissions-jsonl', 'w') as out_file:\n",
        "    for i in range(len(list_dict)):\n",
        "      out_file.write(json.dumps(list_dict[i],ensure_ascii=False))\n",
        "      out_file.write(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.9 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xja2eddS86S6"
      },
      "source": [
        "players_name = [x for x in ner_merge if x[1] == 'B-PER' or x[1] =='I-PER']\n",
        "players_name_occurence_count = Counter(players_name)\n",
        "print(players_name_occurence_count.most_common(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6GvU3iW9DnW"
      },
      "source": [
        "vncorenlp.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fblWUIMAh06N"
      },
      "source": [
        "SCORE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWHDYGjlIgwT",
        "outputId": "62cb8143-719b-4e10-e5f8-0f43ac72442f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sub = pd.read_json(\"/content/submissions-jsonl\",lines = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 18.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRbsyqSyIgwV",
        "outputId": "51cf765f-f88e-4187-a5d1-5079ccf4d021",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "list_dict = []\n",
        "for i in range(1):\n",
        "  test_id = test['test_id'][i]\n",
        "  team1 = sub['match_summary'][i]['players']['team1']\n",
        "  team2 = sub['match_summary'][i]['players']['team2']\n",
        "  text = test['original_doc'][i]\n",
        "  test_id = test['test_id'][i]\n",
        "  size_temp = len(text[\"_source\"][\"body\"])\n",
        "  sentences = [] \n",
        "  for i in range(size_temp):\n",
        "    temp = ((text[\"_source\"][\"body\"][i][\"text\"]))\n",
        "    sentences.append(temp)\n",
        "  s = str()\n",
        "  s = s + ' ' + ' '.join(sentences)\n",
        "  s = s + '. ' + str(text[\"_source\"][\"description\"])\n",
        "  clean_text = s\n",
        "  scores =  []\n",
        "  for j in range(len(clean_text)):\n",
        "    if clean_text[j] == '-' and clean_text[j+2]!='-' and clean_text[j-2]!='-':\n",
        "      if clean_text[j-1].isnumeric() and clean_text[j+1].isnumeric():\n",
        "        scores.append(clean_text[j-1]+clean_text[j]+clean_text[j+1])\n",
        "    if clean_text[j] == '-' and clean_text[j-2].isnumeric() and clean_text[j+2].isnumeric():\n",
        "      scores.append(clean_text[j-2]+clean_text[j]+clean_text[j+2])\n",
        "\n",
        "    if clean_text[j] == '–' and clean_text[j+2]!='–' and clean_text[j-2]!='–':\n",
        "      if clean_text[j-1].isnumeric() and clean_text[j+1].isnumeric():\n",
        "        scores.append(clean_text[j-1]+clean_text[j]+clean_text[j+1])\n",
        "    if clean_text[j] == '–' and clean_text[j-2].isnumeric() and clean_text[j+2].isnumeric():\n",
        "      scores.append(clean_text[j-2]+clean_text[j]+clean_text[j+2])\n",
        "  listA = scores\n",
        "  print(scores)\n",
        "  #print(\"Given List:\\n\",listA)\n",
        "  if (len(listA) == 0):\n",
        "    final_score_1 = 0\n",
        "    final_score_2 = 0\n",
        "  else :\n",
        "    scores_occurence_count = Counter(listA)\n",
        "    #print(team_occurence_count.most_common(2))\n",
        "    final_score_1 = scores_occurence_count.most_common(1)[0][0][0]\n",
        "    final_score_2 = scores_occurence_count.most_common(1)[0][0][2]\n",
        "  d = {\"test_id\": \"%d\"%(test_id), \"match_summary\": {\"players\": {\"team1\": \"%s\"%team1, \"team2\": \"%s\"%team2}, \"score_board\": {\"score1\": \"%s\"%final_score_1, \"score2\": \"%s\"%final_score_2}, \"score_list\": [{\"player_name\": \"\", \"time\": \"\", \"team\": \"\"}], \"card_list\": [{\"player_name\": \"\", \"time\": \"\", \"team\": \"\"}], \"substitution_list\": [{\"player_in\": \"\", \"time\": \"\", \"player_out\": \"\"}]}}\n",
        "  list_dict.append(d)\n",
        "  print(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1-0', '3-0', '1-3', '3-1', '0-3']\n",
            "{'test_id': '21464024', 'match_summary': {'players': {'team1': 'Than Quảng Ninh', 'team2': 'TTXVN'}, 'score_board': {'score1': '1', 'score2': '0'}, 'score_list': [{'player_name': '', 'time': '', 'team': ''}], 'card_list': [{'player_name': '', 'time': '', 'team': ''}], 'substitution_list': [{'player_in': '', 'time': '', 'player_out': ''}]}}\n",
            "time: 51.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}