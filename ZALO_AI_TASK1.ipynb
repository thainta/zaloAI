{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ZALO_AI_TASK1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0xC99JgPzA51X9t+mbpi6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thainta/zaloAI/blob/main/ZALO_AI_TASK1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-rvguzW6RTo"
      },
      "source": [
        "##GET DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v0wa0ZR5iOJ"
      },
      "source": [
        "! wget https://dl.challenge.zalo.ai/news-summarization/data/train.zip\n",
        "! wget https://dl.challenge.zalo.ai/news-summarization/data/public_test.zip \n",
        "! wget https://dl.challenge.zalo.ai/news-summarization/data/public_test_sample_submit.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or_EyhuX6Lnb"
      },
      "source": [
        "! unzip public_test.zip\n",
        "! unzip public_test_sample_submit.zip\n",
        "! unzip train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60IBCnRe6eyg"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 1000)\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "train = pd.read_json(\"/content/train/train.jsonl\", lines = True)\n",
        "test  = pd.read_json(\"/content/public_test/public_test/public_test.jsonl\", lines = True)\n",
        "public_test_sample = pd.read_json(\"/content/public_test/public_test_sample_submit/public_test_sample_submit.jsonl\",lines = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYdYaXjF6p3f"
      },
      "source": [
        "# TRAIN NAME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-ThitvA6v-i"
      },
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtW04CMD6v9l"
      },
      "source": [
        "!pip install vncorenlp\n",
        "! wget https://github.com/vncorenlp/VnCoreNLP/archive/master.zip\n",
        "! wget http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\n",
        "! unzip master.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6akJmWE27NcH"
      },
      "source": [
        "IMPORT LIB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTSm6VdF7Q2i",
        "outputId": "93b3f570-c793-451a-ef51-7affec71da97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from vncorenlp import VnCoreNLP\n",
        "from collections import Counter\n",
        "import pprint as pp\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 71 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87Qxs1PV8OA-",
        "outputId": "20f4d20e-7865-4eba-a51f-90bc5ad17fc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vncorenlp_file = '/content/VnCoreNLP-master/VnCoreNLP-1.1.1.jar'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.03 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fna-k0CQ8PPB"
      },
      "source": [
        "TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r6eiJ8BOxB3"
      },
      "source": [
        "list_dict = []\n",
        "for p in range(19,20): \n",
        "  text = test['original_doc'][p]\n",
        "  test_id = test['test_id'][p]\n",
        "  size_temp = len(text[\"_source\"][\"body\"])\n",
        "  sentences = [] \n",
        "  for p in range(size_temp):\n",
        "    temp = ((text[\"_source\"][\"body\"][p][\"text\"]))\n",
        "    sentences.append(temp)\n",
        "  s = str()\n",
        "  s = s + ' ' + ' '.join(sentences)\n",
        "  s = s + '. ' + str(text[\"_source\"][\"description\"])\n",
        "  clean_text = s\n",
        "  scores =  []\n",
        "  for j in range(len(clean_text)):\n",
        "    if clean_text[j] == '-' and clean_text[j+2]!='-' and clean_text[j-2]!='-':\n",
        "      if clean_text[j-1].isnumeric() and clean_text[j+1].isnumeric():\n",
        "        scores.append(clean_text[j-1]+clean_text[j]+clean_text[j+1])\n",
        "    if clean_text[j] == '-' and clean_text[j-2].isnumeric() and clean_text[j+2].isnumeric():\n",
        "      scores.append(clean_text[j-2]+clean_text[j]+clean_text[j+2])\n",
        "  listA = scores\n",
        "  scores_occurence_count = Counter(listA)\n",
        "  final_score_1=scores_occurence_count.most_common(1)[0][0][0]\n",
        "  final_score_2=scores_occurence_count.most_common(1)[0][0][2]\n",
        "  #print(clean_text)\n",
        "  with VnCoreNLP(vncorenlp_file) as vncorenlp:\n",
        "    ner = list(vncorenlp.ner(clean_text))\n",
        "  print(ner)\n",
        "  ner_merge = sum(ner,[])\n",
        "  soccer_team = [list(x) for x in ner_merge if x[1] == 'B-ORG' or x[1] =='I-ORG' or x[1] =='B-LOC' or x[1] =='I-LOC']\n",
        "  i = 0\n",
        "  while i< (len(soccer_team)):\n",
        "    if i == len(soccer_team) - 1 and soccer_team[i][1] != 'I-LOC' and soccer_team[i][1] != 'I-ORG':\n",
        "      break\n",
        "    if soccer_team[i][1] == 'B-ORG' and soccer_team[i+1][1] == 'I-ORG':\n",
        "      soccer_team[i][0] = soccer_team[i][0] + ' '+ soccer_team[i+1][0]\n",
        "      soccer_team.pop(i+1)\n",
        "    if soccer_team[i][1] == 'B-LOC' and soccer_team[i+1][1] == 'I-LOC':\n",
        "      if soccer_team[i][0][len(soccer_team[i][0])-1] == '.':\n",
        "        soccer_team[i][0] = soccer_team[i][0] +soccer_team[i+1][0]\n",
        "      else:  \n",
        "        soccer_team[i][0] = soccer_team[i][0] + ' ' +soccer_team[i+1][0]\n",
        "      soccer_team.pop(i+1)\n",
        "    i+=1\n",
        "  i = 0\n",
        "  while i < len(soccer_team)-1:\n",
        "    j = i+1\n",
        "    while j < len(soccer_team):\n",
        "      if (soccer_team[i][0] != soccer_team[j][0]):\n",
        "        if (soccer_team[i][0] in soccer_team[j][0]) or (soccer_team[j][0] in soccer_team[i][0]):\n",
        "          if (soccer_team.count(soccer_team[i]) > soccer_team.count(soccer_team[j])) :\n",
        "            t = soccer_team[j]\n",
        "            soccer_team = [x for x in soccer_team if x!= t ]\n",
        "          else :\n",
        "            t = soccer_team[i]\n",
        "            soccer_team = [x for x in soccer_team if x!= t ]\n",
        "          i = 0\n",
        "          j = i+1\n",
        "          continue      \n",
        "      j+=1\n",
        "    i+=1\n",
        "  trash_can = []\n",
        "  i = 0\n",
        "  while i < len(soccer_team):\n",
        "    if soccer_team[i][0] in trash_can:\n",
        "      i+=1\n",
        "      continue\n",
        "    if soccer_team[i][0][0].islower():\n",
        "      t = soccer_team[i]\n",
        "      soccer_team = [x for x in soccer_team if x!= t]\n",
        "      trash_can.append(t)\n",
        "    i+=1\n",
        "  listA = []\n",
        "  for x in soccer_team:\n",
        "    listA.append(tuple(x))\n",
        "  #print(\"Given List:\\n\",listA)\n",
        "  team_occurence_count = Counter(listA)\n",
        "  team1=team_occurence_count.most_common(2)[0][0][0]\n",
        "  team1 = team1.replace('_',' ')\n",
        "  team2 = team_occurence_count.most_common(2)[1][0][0]\n",
        "  team2 = team2.replace('_',' ')\n",
        "  d = {\"test_id\": \"%d\"%(test_id), \"match_summary\": {\"players\": {\"team1\": \"%s\"%team1, \"team2\": \"%s\"%team2}, \"score_board\": {\"score1\": \"0\", \"score2\": \"0\"}, \"score_list\": [{\"player_name\": \"\", \"time\": \"\", \"team\": \"\"}], \"card_list\": [{\"player_name\": \"\", \"time\": \"\", \"team\": \"\"}], \"substitution_list\": [{\"player_in\": \"\", \"time\": \"\", \"player_out\": \"\"}]}}\n",
        "  list_dict.append(d)\n",
        "  ##print(d)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOY3HzLD8ix5"
      },
      "source": [
        "WRITE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0pidDhI8koH"
      },
      "source": [
        "with open('submissions-jsonl', 'w') as out_file:\n",
        "    for i in range(len(list_dict)):\n",
        "      out_file.write(json.dumps(list_dict[i],ensure_ascii=False))\n",
        "      out_file.write(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xja2eddS86S6"
      },
      "source": [
        "players_name = [x for x in ner_merge if x[1] == 'B-PER' or x[1] =='I-PER']\n",
        "players_name_occurence_count = Counter(players_name)\n",
        "print(players_name_occurence_count.most_common(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6GvU3iW9DnW"
      },
      "source": [
        "vncorenlp.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fblWUIMAh06N"
      },
      "source": [
        "SCORE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWHDYGjlIgwT",
        "outputId": "62cb8143-719b-4e10-e5f8-0f43ac72442f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sub = pd.read_json(\"/content/submissions-jsonl\",lines = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 18.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRbsyqSyIgwV"
      },
      "source": [
        "list_dict = []\n",
        "for i in range(1):\n",
        "  test_id = test['test_id'][i]\n",
        "  team1 = sub['match_summary'][i]['players']['team1']\n",
        "  team2 = sub['match_summary'][i]['players']['team2']\n",
        "  text = test['original_doc'][i]\n",
        "  test_id = test['test_id'][i]\n",
        "  size_temp = len(text[\"_source\"][\"body\"])\n",
        "  sentences = [] \n",
        "  for i in range(size_temp):\n",
        "    temp = ((text[\"_source\"][\"body\"][i][\"text\"]))\n",
        "    sentences.append(temp)\n",
        "  s = str()\n",
        "  s = s + ' ' + ' '.join(sentences)\n",
        "  s = s + '. ' + str(text[\"_source\"][\"description\"])\n",
        "  clean_text = s\n",
        "  scores =  []\n",
        "  for j in range(len(clean_text)):\n",
        "    if clean_text[j] == '-' and clean_text[j+2]!='-' and clean_text[j-2]!='-':\n",
        "      if clean_text[j-1].isnumeric() and clean_text[j+1].isnumeric():\n",
        "        scores.append(clean_text[j-1]+clean_text[j]+clean_text[j+1])\n",
        "    if clean_text[j] == '-' and clean_text[j-2].isnumeric() and clean_text[j+2].isnumeric():\n",
        "      scores.append(clean_text[j-2]+clean_text[j]+clean_text[j+2])\n",
        "\n",
        "    if clean_text[j] == '–' and clean_text[j+2]!='–' and clean_text[j-2]!='–':\n",
        "      if clean_text[j-1].isnumeric() and clean_text[j+1].isnumeric():\n",
        "        scores.append(clean_text[j-1]+clean_text[j]+clean_text[j+1])\n",
        "    if clean_text[j] == '–' and clean_text[j-2].isnumeric() and clean_text[j+2].isnumeric():\n",
        "      scores.append(clean_text[j-2]+clean_text[j]+clean_text[j+2])\n",
        "  listA = scores\n",
        "  print(scores)\n",
        "  #print(\"Given List:\\n\",listA)\n",
        "  if (len(listA) == 0):\n",
        "    final_score_1 = 0\n",
        "    final_score_2 = 0\n",
        "  else :\n",
        "    scores_occurence_count = Counter(listA)\n",
        "    #print(team_occurence_count.most_common(2))\n",
        "    final_score_1 = scores_occurence_count.most_common(1)[0][0][0]\n",
        "    final_score_2 = scores_occurence_count.most_common(1)[0][0][2]\n",
        "  d = {\"test_id\": \"%d\"%(test_id), \"match_summary\": {\"players\": {\"team1\": \"%s\"%team1, \"team2\": \"%s\"%team2}, \"score_board\": {\"score1\": \"%s\"%final_score_1, \"score2\": \"%s\"%final_score_2}, \"score_list\": [{\"player_name\": \"\", \"time\": \"\", \"team\": \"\"}], \"card_list\": [{\"player_name\": \"\", \"time\": \"\", \"team\": \"\"}], \"substitution_list\": [{\"player_in\": \"\", \"time\": \"\", \"player_out\": \"\"}]}}\n",
        "  list_dict.append(d)\n",
        "  print(d)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}